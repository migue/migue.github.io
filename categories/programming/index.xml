<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>programming | Just my thouhgts</title>
    <link>https://migue.github.io/categories/programming/</link>
      <atom:link href="https://migue.github.io/categories/programming/index.xml" rel="self" type="application/rss+xml" />
    <description>programming</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 22 Apr 2020 07:35:33 +0200</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>programming</title>
      <link>https://migue.github.io/categories/programming/</link>
    </image>
    
    <item>
      <title>InfluxDB storage subsystem: the TSI files</title>
      <link>https://migue.github.io/post/influx-storage-tsi-component/</link>
      <pubDate>Wed, 22 Apr 2020 07:35:33 +0200</pubDate>
      <guid>https://migue.github.io/post/influx-storage-tsi-component/</guid>
      <description>&lt;p&gt;Final entry on the InfluxDB storage subsystem series. This time I am going to focus on the, relatively new, indexing mechanism that the InfluxDB folks have built into their storage system.&lt;/p&gt;
&lt;p&gt;If you just arrived here for the first time, you can find some more details about the other major components of the storage system in the previous blog posts of the series: 
&lt;a href=&#34;https://migue.github.io/post/quick-tour-influx-storage/&#34;&gt;intro and WAL component&lt;/a&gt;
 and 
&lt;a href=&#34;https://migue.github.io/post/influx-storage-tsm-component/&#34;&gt;tsm component&lt;/a&gt;
.&lt;/p&gt;
&lt;h1 id=&#34;the-origins&#34;&gt;The origins&lt;/h1&gt;
&lt;p&gt;If you recall from the previous posts, the TSM files have an index that allows the database to determine where a certain time series is located when a seriesKey and a time range are provided.&lt;/p&gt;
&lt;p&gt;However, what happens when a more complex query is executed? If instead of just providing a series key the user wants to perform a &lt;strong&gt;group by operation&lt;/strong&gt; using some of the tags, how does the database make sure that it can resolve the query with acceptable performance?&lt;/p&gt;
&lt;p&gt;Seems like an inverted index could help the database to solve the problem, right? Previous to the TSI alternative, InfluxDB had an in-memory inverted index which was built at startup time from the data stored in the TSM files. This approach worked reasonably fine but, what happens when the number of different series starts to grow larger and larger? Is the database able to handle millions of different series in a single machine? The setups I’ve been dealing with are usually in between 10-12 million series and, in a single server with 64G of RAM, I have been struggling with the memory limitations of the in-memory inverted index approach.&lt;/p&gt;
&lt;p&gt;With the previous limitations in mind and the goal to be able to support hundreds of millions of different series in a single machine, the InfluxDB folks decided to build the TSI index as a replacement for the aforementioned in-memory index. This new index aims to remove the upper bound limit set by the memory consumption and tries to enforce that, as the number of different series grow bigger, they have an imperceptible impact on the startup times of the database.&lt;/p&gt;
&lt;p&gt;So, with the development of this new type of index, InfluxDB looks like two databases in one: the time series store we’ve already covered in the previous post and the new inverted index we are going to cover during the next sections.&lt;/p&gt;
&lt;h1 id=&#34;the-tsi-index&#34;&gt;The TSI index&lt;/h1&gt;
&lt;p&gt;This new data structure moves the index from memory to disk and then these files are memory-mapped, letting the underlying operating system to manage the cache for them. I am curious about the reasoning behind this decision, because, in general, you can have your own cache system and make your own caching decisions based on high-level access patterns that, combined with modern cache techniques like 
&lt;a href=&#34;https://arxiv.org/abs/1512.00727&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TinyLFU&lt;/a&gt;
 can get you far ahead. Of course, this second alternative is way more complicated than the memory-mapped one, and probably not worth to invest the required time from your development team (I am just guessing here).&lt;/p&gt;
&lt;p&gt;This new index is very similar to the TSM engine described in the previous post: there’s a write-ahead log similar to the one we described during the first post of the series or a compaction process which is constantly running and merging index into larger files.&lt;/p&gt;
&lt;h2 id=&#34;understanding-the-principal-components&#34;&gt;Understanding the principal components&lt;/h2&gt;
&lt;p&gt;The principal parts of this new index are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Index&lt;/strong&gt;: contains the entire index for a single shard.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Partition&lt;/strong&gt;: contains a sharded partition for a shard&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LogFile&lt;/strong&gt;: contains newly written series as an in-memory index and is persisted as a WAL.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IndexFile&lt;/strong&gt;: contains an immutable, memory-mapped index built from a LogFile or merged from two contiguous index files.
*&lt;strong&gt;SeriesFile&lt;/strong&gt;: contains a set of all the series in the whole database (this file is shared across all the different shards in the database)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-lifecycle-of-a-write-operation&#34;&gt;The lifecycle of a write operation&lt;/h2&gt;
&lt;p&gt;When a new write comes into the system the next steps happen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The ids of the series are looked up or added to the &lt;strong&gt;SeriesFile&lt;/strong&gt; in case it doesn’t exist&lt;/li&gt;
&lt;li&gt;The series is added to the index&lt;/li&gt;
&lt;li&gt;The series is added to a WAL file and a few different in-memory indexes. Similar to the behavior described in the TSM entry (this process is similar to the process we already described in the first post).&lt;/li&gt;
&lt;li&gt;The series and name sketches are updated with the series and name values respectively.&lt;/li&gt;
&lt;li&gt;Once the previous log file grows above a certain threshold (the default is 1MB), a new active log file is created and the previous log file is compacted into an IndexFile.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: the previous sketches serve as an estimator of the series cardinality. They are implemented using a probabilistic data structure named 
&lt;a href=&#34;https://research.google/pubs/pub40671/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HyperLog++&lt;/a&gt;
. The main goal of this data-structure is to estimate the number of different elements in very large sets of data using probabilistic algorithms (probabilistic data-structures are a really nice topic but it’s out of the scope of the post to go deeper on how this internally works).&lt;/p&gt;
&lt;h2 id=&#34;the-structure-of-the-log-file&#34;&gt;The structure of the log file&lt;/h2&gt;
&lt;p&gt;The log file is a list of 
&lt;a href=&#34;https://github.com/influxdata/influxdb/blob/1.8/tsdb/index/tsi1/log_file.go&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LogEntry&lt;/a&gt;
 objects persisted to disk in sequential order:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// LogFile represents an on-disk write-ahead log file.
type LogFile struct {
  mu         sync.RWMutex
  wg         sync.WaitGroup // ref count
  id         int            // file sequence identifier
  data       []byte         // mmap
  file       *os.File       // writer
  w          *bufio.Writer  // buffered writer
  bufferSize int            // The size of the buffer used by the buffered writer
  nosync     bool           // Disables buffer flushing and file syncing. Useful for offline tooling.
  buf        []byte         // marshaling buffer
  keyBuf     []byte
 
  sfile   *tsdb.SeriesFile // series lookup
  size    int64            // tracks current file size
  modTime time.Time        // tracks last time write occurred
 
  // In-memory series existence/tombstone sets.
  seriesIDSet, tombstoneSeriesIDSet *tsdb.SeriesIDSet
 
  // In-memory index.
  mms logMeasurements
 
  // Filepath to the log file.
  path string
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There’re a few different entry types that can be stored in the log: &lt;code&gt;AddSeries&lt;/code&gt;,&lt;code&gt;DeleteSeries&lt;/code&gt;,&lt;code&gt;DeleteMeasurement&lt;/code&gt;, &lt;code&gt;DeleteTagKey&lt;/code&gt;, &lt;code&gt;DeleteTagValue&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;the-structure-of-the-tsi-file&#34;&gt;The structure of the TSI file&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;.tsi&lt;/code&gt; files are inmutable files where the data is indexed and persisted to disk and memory mapped. From a high level perspective, the index file has the following sections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TagBlocks&lt;/strong&gt;: Index of tag values for a single tag key.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MeasurementBlock&lt;/strong&gt;: Index of measurements and their tag keys.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Trailer&lt;/strong&gt;: Offset information for the file and HyperLogLog sketches.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following snippet shows how the different parts of the the &lt;code&gt;tsi&lt;/code&gt; index file are read from the data stored in the disk. I have removed a few lines I didn&amp;rsquo;t consider to be interesting, you can find all the details in the 
&lt;a href=&#34;https://github.com/influxdata/influxdb/blob/1.8/tsdb/index/tsi1/index_file.go#L168&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;original file&lt;/a&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// UnmarshalBinary opens an index from data.
// The byte slice is retained so it must be kept open.
func (f *IndexFile) UnmarshalBinary(data []byte) error {
	// Ensure magic number exists at the beginning.
	if len(data) &amp;lt; len(FileSignature) {
		return io.ErrShortBuffer
	} else if !bytes.Equal(data[:len(FileSignature)], []byte(FileSignature)) {
		return ErrInvalidIndexFile
	}

	// Read index file trailer.
	t, err := ReadIndexFileTrailer(data)
	

	// Slice series sketch data.
	f.sketchData = data[t.SeriesSketch.Offset : t.SeriesSketch.Offset+t.SeriesSketch.Size]
	f.tSketchData = data[t.TombstoneSeriesSketch.Offset : t.TombstoneSeriesSketch.Offset+t.TombstoneSeriesSketch.Size]

	// Slice series set data.
	f.seriesIDSetData = data[t.SeriesIDSet.Offset : t.SeriesIDSet.Offset+t.SeriesIDSet.Size]
	f.tombstoneSeriesIDSetData = data[t.TombstoneSeriesIDSet.Offset : t.TombstoneSeriesIDSet.Offset+t.TombstoneSeriesIDSet.Size]

	// Unmarshal measurement block.
    if err := f.mblk.UnmarshalBinary(data[t.MeasurementBlock.Offset:][:t.MeasurementBlock.Size]); 
    
	// Unmarshal each tag block.
	f.tblks = make(map[string]*TagBlock)
	itr := f.mblk.Iterator()

	for m := itr.Next(); m != nil; m = itr.Next() {
		e := m.(*MeasurementBlockElem)

		// Slice measurement block data.
		buf := data[e.tagBlock.offset:]
		buf = buf[:e.tagBlock.size]

		// Unmarshal measurement block.
		var tblk TagBlock
		if err := tblk.UnmarshalBinary(buf); err != nil {
			return err
		}
		f.tblks[string(e.name)] = &amp;amp;tblk
	}

	// Save reference to entire data block.
	f.data = data

	return nil
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remember that these files are created from the information stored in the &lt;code&gt;LogFiles&lt;/code&gt;, thanks to the compaction process.&lt;/p&gt;
&lt;h1 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h1&gt;
&lt;p&gt;In this post, I’ve covered a few details about the new TSI component of the InfluxDB’s storage engine, trying to explain how this new type of index is organized, how it works and what problems try to solve.&lt;/p&gt;
&lt;p&gt;This is the last post of the InfluxDB storage series. My goal with this series has been to share with you some of the details of how a database internally works (using Influx as the main vehicle to explain the concepts) and some of the different elements that can be found at many different databases (storage formats, write-ahead logs, indexes, …)&lt;/p&gt;
&lt;p&gt;I hope you have enjoyed the whole series (I would like to apologize for my poor English skills). It’s been fun to be back in the blog again and write about something I do enjoy a lot (databases) and, who knows, maybe I will be able to write about any other topic I do enjoy in the near future.&lt;/p&gt;
&lt;p&gt;See you on the Internet!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>InfluxDB storage subsystem: the TSM files</title>
      <link>https://migue.github.io/post/influx-storage-tsm-component/</link>
      <pubDate>Tue, 14 Apr 2020 17:14:30 +0100</pubDate>
      <guid>https://migue.github.io/post/influx-storage-tsm-component/</guid>
      <description>&lt;p&gt;During this entry, we are going through the TSM part of the InfluxDB storage engine: how the contents are organized in the disk, how they are compressed or how they are compacted. This is the second entry of the series about the InfluxDB storage engine started in 
&lt;a href=&#34;https://migue.github.io/post/quick-tour-influx-storage/&#34;&gt;the previous post&lt;/a&gt;
.&lt;/p&gt;
&lt;h1 id=&#34;tsm-files-structure&#34;&gt;TSM files structure&lt;/h1&gt;
&lt;p&gt;The TSM files are where Influx stores the real data; these files are read-only files and are memory-mapped. If you’re familiar with any database using an LSM Tree variant this concept is very similar to the SSTable concept.&lt;/p&gt;
&lt;p&gt;Let’s start with the structure of the files and how they are physically stored. At a high level, the structure is shown in the picture below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://migue.github.io/img/influxdb-tsm-file-structure.png&#34; alt=&#34;TSM File Structure&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-header&#34;&gt;The header&lt;/h2&gt;
&lt;p&gt;The header is a magic number which helps to identify the type of the file (4 bytes) and its version number (1 byte):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://migue.github.io/img/influx-tsm-file-structure-header.png&#34; alt=&#34;TSM File Structure Header Section&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-blocks&#34;&gt;The blocks&lt;/h2&gt;
&lt;p&gt;Blocks are sequences of pairs where every pair is composed of a CRC32 checksum and the data that needs to be stored. The diagram below shows how this part is structured:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://migue.github.io/img/influx-tsm-structure-data-blocks.png&#34; alt=&#34;TSM File Structure Blocks Section&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-index&#34;&gt;The index&lt;/h2&gt;
&lt;p&gt;The index section serves, as its suggest, as the index to the set of blocks in the file and is composed of a sequence of entries lexicographically ordered by key first and then by time. The format of every entry in the previous sequence is shown in the next diagram:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://migue.github.io/img/influx-tsm-structure-index.png&#34; alt=&#34;TSM File Structure Index Section&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;KeyLen&lt;/strong&gt;: represents the length of the key.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key&lt;/strong&gt;: represents the key itself.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt;: represents the type of the field being stored (float, integer, string or bool).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Count&lt;/strong&gt;: represents the number of blocks in the file.
For every block in the TSM file, there is a corresponding entry in the index with the following information:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MinTime&lt;/strong&gt;: minimum time stored in the block&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MaxTime&lt;/strong&gt;: maximum time stored in the block&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Offset&lt;/strong&gt;: the offset into the file where the block is located&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Size&lt;/strong&gt;: the size of the block&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note how this index allows the database to efficiently access all the required blocks. When a key and a date are provided the database knows exactly which file contains the block and where this block is located and how much data needs to be read to retrieve the aforementioned block.&lt;/p&gt;
&lt;h2 id=&#34;the-footer&#34;&gt;The footer&lt;/h2&gt;
&lt;p&gt;The last section of the TMS file is the footer that stores the offset where the index starts.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://migue.github.io/img/influx-tsm-structure-footer.png&#34; alt=&#34;TSM File Structure Footer Section&#34;&gt;&lt;/p&gt;
&lt;p&gt;As we have already mentioned in the previous post, when the cache is full a snapshot is written to the corresponding TSM file:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// WriteSnapshot will snapshot the cache and write a new TSM file with its contents, releasing the snapshot when done.
func (e *Engine) WriteSnapshot() (err error) {
    ...
    
    return e.writeSnapshotAndCommit(log, closedFiles, snapshot)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The previous snippet just highlights where the actual writing process is invoked; you can find more details 
&lt;a href=&#34;https://github.com/influxdata/influxdb/blob/1.8/tsdb/engine/tsm1/engine.go#L1903&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
.&lt;/p&gt;
&lt;h1 id=&#34;tsm-file-compression&#34;&gt;TSM File compression&lt;/h1&gt;
&lt;p&gt;Every data block is actually compressed before being persisted into the disk in order to reduce both IO operations and disk space. The structure of a block is shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://migue.github.io/img/influx-tsm-data-block-structure.png&#34; alt=&#34;TSM Data Block Structure&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you look carefully at the previous picture you can see that timestamps and the actual values are encoded separately, allowing the engine to use timestamp encoding for all the timestamps and the more appropriate encoding for every one of the fields. I think this has been a great decision and the usual compression ratios seem to validate this decision (I’ve seen compression ratios of 1:23, 1:24 in a few differente scenarios).&lt;/p&gt;
&lt;p&gt;Complementing the timestamps and values encodings every block starts with a 1-byte-header where the four higher bits define the compression type and the four lower bits are there for the encoder in case it needs them. Right after this header, using a variable byte encoding mechanism, the length of the timestamps block is stored.&lt;/p&gt;
&lt;p&gt;The compression mechanisms for every type of data are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Timestamps&lt;/strong&gt;: an adaptive approach based on the structure of the timestamps to be encoded is used. It’s a combination of delta encoding, scaling and compression using 
&lt;a href=&#34;https://github.com/jwilder/encoding/blob/master/simple8b/encoding.go&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simple8b&lt;/a&gt;
 run-length encoding (falling back to no compression in case it’s needed). You can find more details about this approach in the 
&lt;a href=&#34;http://www.vldb.org/pvldb/vol8/p1816-teller.pdf?spm=a2c65.11461447.0.0.4a976b213iTmnM&amp;amp;file=p1816-teller.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gorrilla paper&lt;/a&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Floats&lt;/strong&gt;: I think, again, this encoding is based in the aforementioned Gorilla paper. If you’re interested to learn more about it, the paper has a nice explanation about its inner workings.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Integers&lt;/strong&gt;: Two different strategies are used to compress integers depending on the range values of the data that needs to be compressed. As a first step, the values are encoded using 
&lt;a href=&#34;https://developers.google.com/protocol-buffers/docs/encoding#signed-integers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zig Zag encoding&lt;/a&gt;
. If the value is smaller than &lt;code&gt;(1 &amp;lt;&amp;lt; 60) - 1&lt;/code&gt; they are compressed the simple8b algorithm mentioned above and, if they are bigger, they are stored uncompressed. You can see where this decision is made in the next code snippet (extracted from 
&lt;a href=&#34;https://github.com/influxdata/influxdb/blob/1.8/tsdb/engine/tsm1/batch_integer.go#L74&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
):&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;if max &amp;gt; simple8b.MaxValue { // There is an encoded value that&#39;s too big to simple8b encode.
        // Encode uncompressed.
        sz := 1 + len(deltas)*8
        if len(b) &amp;lt; sz &amp;amp;&amp;amp; cap(b) &amp;gt;= sz {
            b = b[:sz]
        } else if len(b) &amp;lt; sz {
            b = append(b, make([]byte, sz-len(b))...)
        }
 
        // 4 high bits of first byte store the encoding type for the block
        b[0] = byte(intUncompressed) &amp;lt;&amp;lt; 4
        for i, v := range deltas {
            binary.BigEndian.PutUint64(b[1+i*8:1+i*8+8], uint64(v))
        }
        return b[:sz], nil
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Booleans&lt;/strong&gt;: they are encoded using a bit packing strategy (each boolean use 1 bit)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strings&lt;/strong&gt;: they are encoded using 
&lt;a href=&#34;http://google.github.io/snappy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Snappy&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;compaction-process&#34;&gt;Compaction process&lt;/h1&gt;
&lt;p&gt;So far we’ve seen how all our points are physically stored in the disk and the reasoning behind the decision to use such data layout.
Aiming to optimize the storage of the previous data from the query perspective, Influx continuously runs a compaction process. There’re a few different levels of compaction types&lt;/p&gt;
&lt;h2 id=&#34;snapshot&#34;&gt;Snapshot&lt;/h2&gt;
&lt;p&gt;We’ve already talked briefly about this process; The values stored in the Cache and the WAL need to be stored in a TSM file in order to save both memory and disk space. If you remember for the previous post, we’ve already described this process in the previous post.&lt;/p&gt;
&lt;h2 id=&#34;leveled-compactions&#34;&gt;Leveled compactions&lt;/h2&gt;
&lt;p&gt;There are 4 different levels of compaction and they occur as the size of the TSM grows. Snapshots are compacted to level-1 files, level-1 files are compacted to level-2 files and so on. When level-4 is reached no further compaction is applied to these files.&lt;/p&gt;
&lt;p&gt;Going deeper into the inner workings of the leveled compaction process would take a whole separate blog entry so I am going to stop here&lt;/p&gt;
&lt;h2 id=&#34;index-optimization&#34;&gt;Index optimization&lt;/h2&gt;
&lt;p&gt;In the scenario where many level-4 TSM files are created, the index becomes larger and the cost of accessing it increases. This optimization tries to split the series across different TSM files, sorting all points for a particular series into the same file.&lt;/p&gt;
&lt;p&gt;Before this process, a TSM file stores points about most of the series and, after the optimization is executed, each of the new TSM files store a reduced number of series (with very little overlap among them).&lt;/p&gt;
&lt;h2 id=&#34;full-compactions&#34;&gt;Full compactions&lt;/h2&gt;
&lt;p&gt;This type of compaction process only runs when a shard has become cold for writes (no new writes are coming into it) or when a delete operation is executed on the shard. This compaction process applies all the techniques used in the leveled compactions and the index optimization process&lt;/p&gt;
&lt;h1 id=&#34;wrapping-up&#34;&gt;Wrapping up&lt;/h1&gt;
&lt;p&gt;In this post, I’ve covered a few details about the TSM part of the InfluxDB’s storage engine, going a little bit deeper into some of the concepts introduced in the first post of this series.&lt;/p&gt;
&lt;p&gt;In the next post, I will try to provide a few details about the TSI files and how this part of the storage subsystem helps Influx to speed up more complex queries.&lt;/p&gt;
&lt;p&gt;Again, we’ve used InfluxDB as the vehicle to show some of the concepts used for building a database: how the information is organized in the disk, compression, efficiently looking for information, … Of course, this will be dependent on the type of database being built.&lt;/p&gt;
&lt;p&gt;Thanks a lot for reading! I hope you have enjoyed it as much as I have done writing it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>InfluxDB storage subsystem: an introduction</title>
      <link>https://migue.github.io/post/quick-tour-influx-storage/</link>
      <pubDate>Tue, 14 Apr 2020 15:14:30 +0100</pubDate>
      <guid>https://migue.github.io/post/quick-tour-influx-storage/</guid>
      <description>&lt;p&gt;Writing on the blog about some of the technical stuff I usually enjoy and/or work with is something that’s always in my plans but I never find the right time do it. Due to all this quarantine related stuff, both my sleeping habits and the kid’s are being somehow affected and, well, here I am, staring at a blank page trying to start writing about databases. And, well, since I don’t longer work for an international company I thought it would be a good idea to somehow practice my poor English skills.&lt;/p&gt;
&lt;p&gt;This time my plan is to write about InfluxDB, a columnar oriented time-series database written in Go, and provide a quick tour of some of the most important characteristics of their storage engine.&lt;/p&gt;
&lt;p&gt;I have been dealing with InfluxDB for a while and I have gone way deeper than I would like to quite a few times but &lt;strong&gt;I am by no means an expert&lt;/strong&gt;, so, please, if I say something that’s not completely accurate, forgive me, and please, correct me.&lt;/p&gt;
&lt;p&gt;I’ve dealt with both the OpenSource and the Enterprise versions but everything here is going to be based on the former (to the best of my knowledge the storage engine is the same in both alternatives). The details included later in the post are based on the 1.8.x and 1.7.x branches (I know the 2.0 introduces quite a lot changes but I won’t talk about them here).&lt;/p&gt;
&lt;h1 id=&#34;before-getting-started&#34;&gt;Before getting started&lt;/h1&gt;
&lt;p&gt;Influx has gone through different storage engines through its short lifetime: LevelDB, BoltDB (not sure if there’s anymore) and, and this is just an educated guess, any of them completely satisfied the requirements that the InfluxDB folks were looking for: large batch deletes, hot backups, high throughput or a good compression performance among many others. So, in order to solve the previous points (it’s not an exhaustive list), they decided to go on their own and write a new storage engine (it&amp;rsquo;s a brave bet).&lt;/p&gt;
&lt;p&gt;Everything I am going to write about here is focused on this storage engine and I have no experience with the Influx versions where the underlying storage engine was LevelDB or BoltDB.&lt;/p&gt;
&lt;h1 id=&#34;influxdb-concepts&#34;&gt;InfluxDB concepts&lt;/h1&gt;
&lt;p&gt;Before we go into the details of the storage engine let me introduce a few concepts I think all of us should know about.&lt;/p&gt;
&lt;p&gt;Everything starts with a database concept, similar to a traditional RDBMS, which acts as the container of many of the capabilities that Influx provides: user management, retention policies, continuous queries, … Everything related to a database is represented under a folder in the filesystem.&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;retention policy&lt;/strong&gt; describes how long the data is kept around and how many copies of this data are stored in the cluster (for the OpenSource version the replication setting has no effect).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Measurements&lt;/strong&gt; are the “data structure” used to model how the data is stored in Influx and the fields associated with it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fields&lt;/strong&gt; represent the actual data value. These are required and, something really important, they are not indexed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tags&lt;/strong&gt; represents metadata associated with the aforementioned fields. They are optional, but they are very useful because they are indexed and allow you to perform group by and/or filter operations (you can filter on fields as well, but since they are not indexed, this is not a performant operation).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Series&lt;/strong&gt; are a logical grouping of data defined by a measurement, a set of tags and a field. To me, this is one of the most important concepts that need to be clear while working with InfluxDB, because many of the different concepts revolve around it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Shards&lt;/strong&gt;  contains the actual encoded and compressed data. They are represented by a TSM file on disk (more on this later). Every shard contains a specific set of series so all the points falling on a given series will be stored in the same shard.&lt;/p&gt;
&lt;p&gt;In order to get your data points inserted into the database, Influx defines a text-based protocol named &lt;strong&gt;line protocol&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;An example of how a single data point looks like in the &lt;strong&gt;line protocol&lt;/strong&gt; and how it maps to the concepts described before is shown in the picture below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://migue.github.io/img/influx-line-protocol.png&#34; alt=&#34;Influx Line Protocol&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;influxdb-storage-engine&#34;&gt;InfluxDB storage engine&lt;/h1&gt;
&lt;p&gt;At the beginning of the post, I described some of the features that, per my understanding, the Influx folks were looking for when building their storage engine and how all these requirements led them to their current storage solution.&lt;/p&gt;
&lt;p&gt;Their storage solution is similar to an LSM Tree and, from a high-level perspective, it is composed by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A write-ahead log&lt;/li&gt;
&lt;li&gt;A collection of &lt;strong&gt;TSM&lt;/strong&gt; (read-only) files where the actual time series data is stored (similar to the SSTables)&lt;/li&gt;
&lt;li&gt;TSI files that serve as the inverted index used to quickly access the information. Prior to this version of the index, the data was held into an in-memory data structure, making it difficult to support high-cardinality scenarios (millions of series).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before we move forward, a short note about how I plan to organize the contents. The original idea was to put everything I wanted to write down into a single post but it would be probably a little bit dense so I have decided to split it into 3 different parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The current one with the introduction to Influx, the overview of the storage engine and a quick tour around the WAL component and its cache counterpart.&lt;/li&gt;
&lt;li&gt;The second one will cover the details about the TSM.&lt;/li&gt;
&lt;li&gt;The third one will cover details about the TSI.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For this post, let’s try to go a little bit deeper into the write ahead log (WAL) and its cache counterpart.&lt;/p&gt;
&lt;h2 id=&#34;write-ahead-log-wal&#34;&gt;Write ahead log (WAL)&lt;/h2&gt;
&lt;p&gt;The WAL is a write-optimized data structure that allows the writes to be durable and its main goal is to allow the writes to be appended as fast as possible so it is not easily queryable.&lt;/p&gt;
&lt;p&gt;When a new write comes into the system the new points are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stored at an in-memory cache (more about this in the next section).&lt;/li&gt;
&lt;li&gt;Serialized, compressed using Snappy and written to the WAL.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we take a look at the 
&lt;a href=&#34;https://github.com/influxdata/influxdb/blob/1.8/tsdb/engine/tsm1/engine.go#L1367&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;source code&lt;/a&gt;
 we can see where this actually happens:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// WritePoints writes metadata and point data into the engine.
// It returns an error if new points are added to an existing key.
func (e *Engine) WritePoints(points []models.Point) error {
    ….
    // first try to write to the cache
    if err := e.Cache.WriteMulti(values); err != nil {
        return err
    }
 
    if e.WALEnabled {
        if _, err := e.WAL.WriteMulti(values); err != nil {
            return err
        }
    }
    return seriesErr
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we could disable the WAL and, in this case, writes will only exist in the cache and could be lost if a cache snapshot has not happened.&lt;/p&gt;
&lt;p&gt;The format used to describe every one of the entries appended to the WAL follows a type-length-value encoding scheme with a single byte representing the type of the entry being stored (write, delete or a range delete), a 4 byte uint32 representing the length of the compressed block, followed by the actual compressed data block.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://migue.github.io/img/wal-entry-encoding.png&#34; alt=&#34;Wal entry encoding&#34;&gt;&lt;/p&gt;
&lt;p&gt;Looking again at the 
&lt;a href=&#34;https://github.com/influxdata/influxdb/blob/1.8/tsdb/engine/tsm1/wal.go#L1062&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;source code&lt;/a&gt;
 here we can see how the actual writing is performed:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Write writes entryType and the buffer containing compressed entry data.
func (w *WALSegmentWriter) Write(entryType WalEntryType, compressed []byte) error {
    var buf [5]byte
    buf[0] = byte(entryType)
    binary.BigEndian.PutUint32(buf[1:5], uint32(len(compressed)))
 
    if _, err := w.bw.Write(buf[:]); err != nil {
        return err
    }
 
    if _, err := w.bw.Write(compressed); err != nil {
        return err
    }
 
    w.size += len(buf) + len(compressed)
 
    return nil
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;cache&#34;&gt;Cache&lt;/h2&gt;
&lt;p&gt;The cache component is an in-memory data structure that holds a copy of all the points persisted in the WAL. As we’ve already mentioned in the previous section, when a new write comes into the system the new points are stored in this cache.&lt;/p&gt;
&lt;p&gt;The aforementioned points are indexed by the key which is formed by the measurement name, the tag set and the unique field key. If we go back to our previous example where we had a single write coming into the system:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;infrastructure_metrics,server=server-1,container=container-1 cpu_usage=82
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The key would be represented by something like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://migue.github.io/img/wal-cache-key.png&#34; alt=&#34;WAL Cache Key&#34;&gt;&lt;/p&gt;
&lt;p&gt;The points stored in the cache are not compressed and an upper bound can be set so we can prevent unexpected out of memory situations (if the upper bound limit is exceeded new writes coming into the system will be rejected) and prevent the database service to be unexpectedly restarted.&lt;/p&gt;
&lt;p&gt;When the number of elements in the cache reaches a certain lower bound (it’s configurable as well) a snapshot of the cache is triggered to a TSM file and the corresponding WAL segment files are removed.&lt;/p&gt;
&lt;p&gt;If we take a quick look to the 
&lt;a href=&#34;https://github.com/influxdata/influxdb/blob/1.8/tsdb/engine/tsm1/engine.go#L1968&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;source code&lt;/a&gt;
 we can see the behavior described in the previous paragraph:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// compactCache continually checks if the WAL cache should be written to disk.
func (e *Engine) compactCache() {
    t := time.NewTicker(time.Second)
    defer t.Stop()
    for {
        e.mu.RLock()
        quit := e.snapDone
        e.mu.RUnlock()
 
        select {
        case &amp;lt;-quit:
            return
 
        case &amp;lt;-t.C:
            e.Cache.UpdateAge()
            if e.ShouldCompactCache(time.Now()) {
                start := time.Now()
                e.traceLogger.Info(&amp;quot;Compacting cache&amp;quot;, zap.String(&amp;quot;path&amp;quot;, e.path))
                err := e.WriteSnapshot()
                if err != nil &amp;amp;&amp;amp; err != errCompactionsDisabled {
                    e.logger.Info(&amp;quot;Error writing snapshot&amp;quot;, zap.Error(err))
                    atomic.AddInt64(&amp;amp;e.stats.CacheCompactionErrors, 1)
                } else {
                    atomic.AddInt64(&amp;amp;e.stats.CacheCompactions, 1)
                }
                atomic.AddInt64(&amp;amp;e.stats.CacheCompactionDuration, time.Since(start).Nanoseconds())
            }
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When a new read operation is received, the storage engine will merge data from the TSM files with the data stored in the cache (so you can read data that hasn’t been snapshotted into the TSM files yet). At query processing time, a copy of the data is done so any new write coming into the system won’t affect the results of any running query.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This post has been a short intro to InfluxDB and a brief overview of its storage subsystem. In addition to the previous intros, we’ve covered a few details of the WAL + Cache storage subsystem elements. As I have already mentioned, my idea is to publish two more posts: one of them covering a few details of the TSM part and the other one going through the inner workings of the TSI component.&lt;/p&gt;
&lt;p&gt;Of course, I am aware this is just an introduction, and the devil is in the details, but I do hope this provides you some insights into a few database design concepts and how a concrete database applies them.&lt;/p&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Books and Talks</title>
      <link>https://migue.github.io/post/books-and-talks/</link>
      <pubDate>Mon, 03 Feb 2020 15:14:30 +0100</pubDate>
      <guid>https://migue.github.io/post/books-and-talks/</guid>
      <description>&lt;p&gt;I would like to share with you a bunch of the tech talks I have recently watched or some of the latest books I have enjoyed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: this list is just a set of resources I have gone through more or less &amp;ldquo;recently&amp;rdquo; about a few different topics I use to enjoy. It&amp;rsquo;s not my goal to create a &amp;ldquo;Best Talks/Papers/Whatever List&amp;rdquo;, just wanted to share with you all some of the things I have found interesting lately (all the resources are listed in no specific order).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disclaimer 2&lt;/strong&gt;: by &amp;ldquo;lately&amp;rdquo; I mean the last ~1.5 years, so probably many of the contents linked below will be quite old for most of you (I have slowed down a lot on my work-related stuff, but this is a different story).&lt;/p&gt;
&lt;p&gt;If you do like databases, systems engineering, cloud computing, runtimes and low-level programming, this list might contain some pointers to a book/talk you could enjoy.&lt;/p&gt;
&lt;h2 id=&#34;talks&#34;&gt;Talks&lt;/h2&gt;
&lt;h3 id=&#34;lets-talk-locks-by-kavya-joshi&#34;&gt;Let&amp;rsquo;s Talk Locks! by Kavya Joshi&lt;/h3&gt;
&lt;p&gt;An amazing talk about how locks are used at different places (Linux syscalls, Go programming language) and its performance implications.&lt;/p&gt;
&lt;p&gt;Actually, any talk coming from Kavya is usually wonderful.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.infoq.com/presentations/go-locks/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;ebtree--design-for-a-scheduler-and-use-almost-everywhere-by-andjelko-iharos&#34;&gt;EBtree — Design for a Scheduler and Use (Almost) Everywhere by Andjelko Iharos&lt;/h3&gt;
&lt;p&gt;This talk goes into the evolution of HAProxy’s internals and how the created the EBTree data structure in order to manage active and suspended tasks within their scheduler (and how they ended up using it almost everywhere)&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.infoq.com/presentations/ebtree-design/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;performance-matters-by-emery-berger&#34;&gt;Performance Matters by Emery Berger&lt;/h3&gt;
&lt;p&gt;I simply love this talk. Emery goes through many of the different factors that, potentially, can affect performance on modern hardware: memory layout, instruction prefetching, branch prediction, &amp;hellip; and some surprising ones like env variables.&lt;/p&gt;
&lt;p&gt;During the talk, he presents the &lt;strong&gt;stabilizer&lt;/strong&gt; tool which randomizes programs layouts during runtime and introduced 
&lt;a href=&#34;https://www.usenix.org/node/196222&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;coz&lt;/a&gt;
, a causal profiler.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=r-TLSBdHe1A&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;pid-loops-and-the-art-of-keeping-systems-stable-by-colm-maccárthaigh&#34;&gt;PID Loops and the Art of Keeping Systems Stable by Colm MacCárthaigh&lt;/h3&gt;
&lt;p&gt;I like Colm&amp;rsquo;s talks a lot. In this case, the talk goes through PID loops, control theory and how a bunch of AWS systems apply these design principles.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.infoq.com/presentations/pid-loops/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;structured-concurrency-by-roman-elizarov&#34;&gt;Structured Concurrency by Roman Elizarov&lt;/h3&gt;
&lt;p&gt;Great talk about the evolution of asynchronous APIS in different programming languages and platforms and how they have applied the structured concurrency concepts to the design of the Kotlin&amp;rsquo;s concurrency libraries.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=Mj5P47F6nJg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;reduce-your-storage-costs-with-transient-replication-and-cheap-quorums-by-alex-petrov&#34;&gt;Reduce your storage costs with Transient Replication and Cheap Quorums by Alex Petrov&lt;/h3&gt;
&lt;p&gt;Alex talks about 
&lt;a href=&#34;http://www2.cs.uh.edu/~paris/MYPAPERS/Icdcs86.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Voting With Witnesses&lt;/a&gt;
 a replication schema which is used in Google Spanner and Megastore and has inspired Apache Cassandra&amp;rsquo;s Transient Replication and Cheap Quorums implementation&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=pEtRBid5oeA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;ftrace-where-modifying-a-running-kernel-all-started-by-steven-rostedt&#34;&gt;ftrace: Where modifying a running kernel all started by Steven Rostedt&lt;/h3&gt;
&lt;p&gt;If you&amp;rsquo;ve ever wondered how tracing works in the Linux kernel you should probably watch it. A highly technical talk but really well executed even an stupid like myself could &lt;em&gt;understand&lt;/em&gt; it.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=93uE_kWWQjs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;applicable-and-achievable-formal-verification-by-heidy-khlaaf&#34;&gt;Applicable and Achievable Formal Verification by Heidy Khlaaf&lt;/h3&gt;
&lt;p&gt;Heidy provides a nice overview of a few verification tools and techniques deployed in the safety critical industry and shows how this could be adapted to your systems.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=GIYtzygBgA4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;correctness-proofs-of-distributed-systems-with-isabellehol-by--martin-kleppmann&#34;&gt;Correctness proofs of distributed systems with Isabelle/HOL by  Martin Kleppmann&lt;/h3&gt;
&lt;p&gt;An extended version of the talk that Martin did at 
&lt;a href=&#34;https://www.youtube.com/watch?v=7w4KC6i9Yac&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Strange Loop 2019&lt;/a&gt;
. He explores how Isabelle can be used to analyze algorithms used in distributed systems, and prove them correct.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.youtube.com/watch?v=Uav5jWHNghY&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Video&lt;/a&gt;
&lt;/p&gt;
&lt;h2 id=&#34;books&#34;&gt;Books&lt;/h2&gt;
&lt;h3 id=&#34;database-internals-by-alex-petrov&#34;&gt;Database internals by Alex Petrov&lt;/h3&gt;
&lt;p&gt;Alex has done an amazing job writing this book. You will find different topics: storage engines like BTrees and LSMs, how data is physically stored and the different building blocks involved, distributed systems and database clustering among many others&lt;/p&gt;
&lt;p&gt;If you like databases and its internals this book is going to be a fun read.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://shop.oreilly.com/product/0636920174462.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;O&amp;rsquo;Reilly&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;serious-cryptography-by-jean-philippe-aumasson&#34;&gt;Serious Cryptography by Jean-Philippe Aumasson&lt;/h3&gt;
&lt;p&gt;Another wonderful book. A practical guide to modern encryption that goes through the fundamental mathematical concepts at the heart of cryptography: authenticated encryption, hash functions, block ciphers, and public-key techniques (RSA and elliptic curve cryptography).&lt;/p&gt;
&lt;p&gt;Totally recommended if you want to learn a little bit more about cryptography, and, even if you&amp;rsquo;re a seasoned practitioner (not my case) I think you can learn a few things.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://shop.oreilly.com/product/9781593278267.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;O&amp;rsquo;Reilly&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;optimizing-java-by-benjamin-evans-james-gough-and-chris-newland&#34;&gt;Optimizing Java By Benjamin Evans, James Gough, and Chris Newland&lt;/h3&gt;
&lt;p&gt;One more book I have enjoyed a lot. A practical approach to JVM performance tuning and how to identify and solve performance related issues. The book will help you to understand Java platform&amp;rsquo;s internals (if you&amp;rsquo;re willing to go through it :) )&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://shop.oreilly.com/product/0636920042983.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;O&amp;rsquo;Reilly&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;efficient-io-with-io_uring&#34;&gt;Efficient IO with io_uring&lt;/h3&gt;
&lt;p&gt;I wasn&amp;rsquo;t sure where to put this resource; technically this is not a book, nor a paper either. Anyway, this is a gorgeous read about the newest Linux IO interface, io_uring and compare it to the current alternatives.&lt;/p&gt;
&lt;p&gt;Why this work is being done, how this works, &amp;hellip; IO_URING is a huge step forward in the Linux kernel and this short introduction provides a gentle introduction&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://kernel.dk/io_uring.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IO_URING introduction&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;cloud-native-data-center-networking-by-dinesh-dutt&#34;&gt;Cloud Native Data Center Networking By Dinesh Dutt&lt;/h3&gt;
&lt;p&gt;A really nice read about how modern cloud native data centers networks work and the steps required to design a datacenter that&amp;rsquo;s reliable and easy to manage. A mix of theory and practice which tries to guide the reader through everything which is needed to create and operate a network infrastructure in a modern datacenter.&lt;/p&gt;
&lt;p&gt;The book covers many different topics: network disaggregation, routing protocols, network virtualization, &amp;hellip;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://shop.oreilly.com/product/0636920217930.do&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;O&amp;rsquo;Reilly&lt;/a&gt;
&lt;/p&gt;
&lt;h3 id=&#34;bpf-performance-tools-linux-system-and-application-observability-by-brendan-gregg&#34;&gt;BPF Performance Tools: Linux System and Application Observability by Brendan Gregg&lt;/h3&gt;
&lt;p&gt;I am still going through it, but I am enjoying it so much I thought I should include it in this list. A really comprehensive guide about BPF tools, performance engineering, and kernel internals. The book includes tons of examples,tools, &amp;hellip;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.oreilly.com/library/view/bpf-performance-tools/9780136588870/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;O&amp;rsquo;Reilly&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;My original idea was to include a section with the papers I have recently enjoyed as well, but the post had become way too long that I decided to split it and do a follow-up including the academic papers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Java Compiler String Addition</title>
      <link>https://migue.github.io/post/java-compiler-string-addition/</link>
      <pubDate>Mon, 21 Apr 2014 22:29:06 +0100</pubDate>
      <guid>https://migue.github.io/post/java-compiler-string-addition/</guid>
      <description>&lt;p&gt;Lately I have seen quite a few misconceptions regarding how string concatenation is handled in the Java world so I would like to write this short blog entry with a couple of stupid examples in order to show the basics of how it is done.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I am focusing here in the bytecode generated by the Java compiler, regardless any optimization the runtime could apply.&lt;/p&gt;
&lt;h3 id=&#34;concatenating-constant-strings&#34;&gt;Concatenating constant strings&lt;/h3&gt;
&lt;p&gt;Imagine we are writing a new class where we have defined three final string fields and we want to add a new method which just returns the sum of the three:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;StringConcatenation&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;

        &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;final&lt;/span&gt; String A &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; B&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; C&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;C&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;

        &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; String &lt;span style=&#34;color:#a6e22e&#34;&gt;concatFinalStrings&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; A &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; B &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; C&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Taking a look to the bytecode generated by the Java compiler we can see the following (I have included only the relevant parts of the command java -v for the sake of clarity):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bytecode&#34; data-lang=&#34;bytecode&#34;&gt;Constant pool:
   ...
   #9 = String             #49            //  ABC
   ...

  public java.lang.String concatFinalStrings();
    descriptor: ()Ljava/lang/String;
    flags: ACC_PUBLIC
    Code:
      stack=1, locals=1, args_size=1
         0: ldc           #9                  // String ABC
         2: areturn
      LineNumberTable
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The previous snippet shows how the Java compiler will generate for us a new constant (position 9 of the constants pool) containing the concatentation of the three strings, and the implementation of the method is just an &lt;strong&gt;ldc&lt;/strong&gt; instruction. As far as I remember, the JLS specifies that compile time constants should end up in an internted string&lt;/p&gt;
&lt;p&gt;For the reader: remove the final modifier at the fields declaration and analyze the generated bytecode. Do you see any difference?&lt;/p&gt;
&lt;h3 id=&#34;concatenating-non-constant-strings&#34;&gt;Concatenating non constant strings&lt;/h3&gt;
&lt;p&gt;The example shown at the previous section could be very unrealistic for many of you so let&amp;rsquo;s see if we can get something more interesting in place. Now we are planning to add a new method which just invokes three other methods and links together the results , like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;StringConcatenation&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;

        &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; String &lt;span style=&#34;color:#a6e22e&#34;&gt;concatVariableStrings&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
                &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; getA&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; getB&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; getC&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt;
        &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;

        &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; String &lt;span style=&#34;color:#a6e22e&#34;&gt;getA&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;A&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; String &lt;span style=&#34;color:#a6e22e&#34;&gt;getB&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;B&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
        &lt;span style=&#34;color:#66d9ef&#34;&gt;public&lt;/span&gt; String &lt;span style=&#34;color:#a6e22e&#34;&gt;getC&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;C&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Taking a closer look at the generated bytecode (again just included the most important sections):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bytecode&#34; data-lang=&#34;bytecode&#34;&gt;  public java.lang.String concatVariableStrings();
    descriptor: ()Ljava/lang/String;
    flags: ACC_PUBLIC
    Code:
      stack=2, locals=1, args_size=1
         0: new           #8                  // class java/lang/StringBuilder
         3: dup
         4: invokespecial #9                  // Method java/lang/StringBuilder.&#34;&lt;init&gt;&#34;:()V
         7: aload_0
         8: invokevirtual #12                 // Method getA:()Ljava/lang/String;
        11: invokevirtual #10                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
        14: aload_0
        15: invokevirtual #13                 // Method getB:()Ljava/lang/String;
        18: invokevirtual #10                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
        21: aload_0
        22: invokevirtual #14                 // Method getC:()Ljava/lang/String;
        25: invokevirtual #10                 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;
        28: invokevirtual #11                 // Method java/lang/StringBuilder.toString:()Ljava/lang/String;
        31: areturn
      LineNumberTable:
        line 12: 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we can see the Java compiler is creating a &lt;strong&gt;StringBuilder&lt;/strong&gt; under the hood, so no temporary String objects are allocated in order to compose the final string which needs to be returned from the method. If you need to improve the performance, you should write the builder by your own, setting the initial size in the constructor.&lt;/p&gt;
&lt;p&gt;Maybe this is not new for you (as it should be), but, lately, I have received quite a few questions regarding this behaviour.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Environment&lt;/strong&gt;: I have used &lt;strong&gt;javac&lt;/strong&gt; and &lt;strong&gt;javap 1.8.0_05&lt;/strong&gt; in OSx to compile the examples.&lt;/p&gt;
&lt;h3 id=&#34;for-the-curious&#34;&gt;For the curious&lt;/h3&gt;
&lt;p&gt;If you &amp;ldquo;port&amp;rdquo; the previous examples to Scala and take a look to the generated bytecode (of the second example), you will see that the Scala compiler will use the same approach shown before; generating a &lt;strong&gt;StringBuilder (scala.collection.mutable.StringBuilder)&lt;/strong&gt; under the covers.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
